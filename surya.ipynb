{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa540d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae969e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"sample_ocr_image.png\")\n",
    "recognition_predictor = RecognitionPredictor()\n",
    "detection_predictor = DetectionPredictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c549835",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = recognition_predictor([image], det_predictor=detection_predictor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede46bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surya.layout import LayoutPredictor\n",
    "\n",
    "image = Image.open(\"sample_ocr_image.png\")\n",
    "layout_predictor = LayoutPredictor()\n",
    "\n",
    "# layout_predictions is a list of dicts, one per image\n",
    "layout_predictions = layout_predictor([image])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "layout_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff97c126",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from surya.recognition import RecognitionPredictor\n",
    "from surya.detection import DetectionPredictor\n",
    "from surya.layout import LayoutPredictor\n",
    "\n",
    "# Initialize models\n",
    "layout_predictor = LayoutPredictor()\n",
    "detection_predictor = DetectionPredictor()\n",
    "recognition_predictor = RecognitionPredictor()\n",
    "\n",
    "# Load image\n",
    "image = Image.open(\"sample_ocr_image.png\").convert(\"RGB\")\n",
    "\n",
    "# 1. Layout analysis\n",
    "layout_predictions = layout_predictor([image])\n",
    "layout_boxes = layout_predictions[0].bboxes  # List[LayoutBox]\n",
    "\n",
    "# Sort by reading order\n",
    "layout_boxes = sorted(layout_boxes, key=lambda x: x.position)\n",
    "\n",
    "full_text_blocks = []\n",
    "\n",
    "# 2. Process each layout block\n",
    "for layout_box in layout_boxes:\n",
    "    x1, y1, x2, y2 = layout_box.bbox\n",
    "    cropped_image = image.crop((x1, y1, x2, y2))\n",
    "\n",
    "    # Recognize text inside cropped region\n",
    "    predictions = recognition_predictor([cropped_image], det_predictor=detection_predictor)\n",
    "\n",
    "    if not predictions or len(predictions[0].text_lines) == 0:\n",
    "        continue  # Skip if no text detected\n",
    "\n",
    "    text_lines = predictions[0].text_lines\n",
    "    block_text = \"\\n\".join([line.text for line in text_lines])\n",
    "\n",
    "    if block_text.strip():\n",
    "        full_text_blocks.append(block_text)\n",
    "\n",
    "# Combine everything into final text\n",
    "final_text = \"\\n\\n\".join(full_text_blocks)\n",
    "\n",
    "print(\"=== FULL OCR TEXT ===\")\n",
    "print(final_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e8e259",
   "metadata": {},
   "source": [
    " ## TROCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78d1befd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at microsoft/trocr-base-printed and are newly initialized: ['encoder.pooler.dense.bias', 'encoder.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "import requests\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-base-printed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7d1ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITEMOUNT\n"
     ]
    }
   ],
   "source": [
    "#image = cv2.imread('sample_ocr_image.png')\n",
    "url = \"https://jeroen.github.io/images/testocr.png\"\n",
    "image = Image.open(requests.get(url, stream=True).raw).convert(\"RGB\")\n",
    "\n",
    "\n",
    "pixel_values = processor(image, return_tensors=\"pt\").pixel_values\n",
    "generated_ids = model.generate(pixel_values)\n",
    "\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634031f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surya-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
